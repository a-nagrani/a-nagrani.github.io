<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="assets/css/normalize.css' %}">
  <link rel="stylesheet" href="assets/css/skeleton.css' %}">
  <link rel="stylesheet" href="assets/css/general.css' %}">
  <link rel="stylesheet" href="assets/css/custom.css' %}">
  <link rel="stylesheet" href="assets/css/styles.css">

  <!-- Start : Google Analytics Code -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-118782745-1"></script>
  <script>
   window.dataLayer = window.dataLayer || [];
   function gtag(){dataLayer.push(arguments);}
   gtag('js', new Date());

   gtag('config', 'UA-118782745-1');

   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-118782745-1', 'auto');
    ga('send', 'pageview');




 </script>
 <!-- End : Google Analytics Code -->

 <script type="text/javascript" src="resources/hidebib.js"></script>
 <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
 <head>
  <title>MBT</title>
  <meta property='og:title' content='Attention Bottlenecks for Multimodal Fusion' />
  <meta property="og:description" content="Arsha Nagrani, Attention Bottlenecks for Multimodal Fusion" />
  <meta property='og:url' content='TODO' />
</head>

<body>
  <br>
  </br>
</br>
  <center>
     <span style="font-size:40px;color:Navy"><b>Attention Bottlenecks for Multimodal Fusion </span></b>
</br>
</br>
</br>
    <table align=center width=1000px>
      <tr>
        <td align=center width=150px>
          <center>
            <span style="font-size:20px"><a href="http://www.robots.ox.ac.uk/~arsha/" target="_blank">Arsha Nagrani</a></span>
          </center>
        </td>
	 <td align=center width=150px>
          <center>
            <span style="font-size:20px"><a href="https://shanyang.me/" target="_blank">Shan Yang</a></span>
          </center>
		</td>
	<td align=center width=150px>
          <center>
            <span style="font-size:20px"><a href="https://scholar.google.co.uk/citations?user=l2FS2_IAAAAJ&hl=en" target="_blank">Anurag Arnab</a></span>
          </center>
        </td>
      </tr>
      <tr>
	
	 <td align=center width=150px>
          <center>
            <span style="font-size:20px"><a href="" target="_blank">Aren Jansen</a></span>
          </center>
        </td>
        <td align=center width=150px>
          <center>
            <span style="font-size:20px"><a href="https://thoth.inrialpes.fr/~schmid/" target="_blank">Cordelia Schmid</a></span>
          </center>
        </td>
       <td align=center width=150px>
          <center>
            <span style="font-size:20px"><a href="https://chensun.me/" target="_blank">Chen Sun</a></span>
          </center>
        </td>
      </tr>
    </table>
    <table align=center width=1000px>
      <tr>
        <td align=center width=100px>
          <center>
            <span style="font-size:18px"></span>
          </center>
        </td>
        <td align=center width=500px>
          <center>
            <span style="font-size:25px"> Google Research</span>
          </center>
        </td>
        <td align=center width=100px>
        </br>
        </br>
          <center>
            <span style="font-size:14px"> </span>
          </center>
        </td>
      </table>

         <table align=center width=500px>
          <!--<tr>
            <td align=center width=200px><center><span style="font-size:24px"><a href="https://arxiv.org/abs/1804.00326">link to paper</a></span>&nbsp;<a href="./assets/bibtex_CVPR2018.txt">[Bibtex]</a></center></td>

            <tr/> -->
          </table><br/>
        </center>

      <!-- Primary Page Layout
      –––––––––––––––––––––––––––––––––––––––––––––––––– -->
       <center>

        <div class="container">
          <div class="row">
            <center>
              <div class="twelve columns" style="margin-top: 3%">
                <div class="row" align=center>
                  <img width="800" class="center" src="assets/images/bottlenecks-2.png">
			<!--
                  <table align=center width=1000px>
                    <tr>
                        <td width=1000px>
                                <font size="4">
                                    Unlike late fusion (left), where no cross-modal information is exchanged in the model until after the classifier, we investigate two pathways for the exchange of cross-modal information. The first is via standard pairwise self attention across all hidden units in a layer, but applied only to later layers in the model -- mid fusion (middle, left). 
    We also propose the use of `fusion bottlenecks' (middle, right) that restrict attention flow within a layer through tight latent units. Both forms of restriction can be applied in conjunction (Bottleneck Mid Fusion) for optimal performance (right). We show B=2 bottleneck units and 3 hidden units per modality. Grey boxes indicate tokens that receive attention flow from both audio and video tokens.
                                  </font>
                          </td>
                    </tr>

                  </table> -->
  
              </div> 
              <div class="container">  
          <div class="row" align="justify"> 
                <h2 class="section-title"><span>Abstract</span></h2>
		<p>
		  Humans perceive the world by concurrently processing and fusing high-dimensional inputs from multiple modalities such as vision and audio. Machine

perception models, in stark contrast, are typically modality-specific and optimised
for unimodal benchmarks. A common approach for building multimodal models is
to simply combine multiple of these modality-specific architectures using late-stage
fusion of final representations or predictions ("late-fusion"). Instead, we introduce a
novel transformer based architecture that fuses multimodal information at multiple layers, via "cross-modal bottlenecks".  Unlike traditional pairwise self-attention, these bottlenecks force information between different modalities to pass through a small
number of "bottleneck" latent units, requiring the model to collate and condense the
most relevant information in each modality and only share what is necessary. We
find that such a strategy improves fusion performance, at the same time reducing

computational cost. We conduct thorough ablation studies, and achieve state-of-the-
art results on multiple audio-visual classification benchmarks including Audioset,

		  Epic-Kitchens and VGGSound. All code and models will be released.
		  
		</p>
		      </div>
		<div class="row" align=center>
		  <!-- <img width="800" class="center" src="assets/images/pipeline.png"> -->
			</br>
		      </br>
		      
                                  Using attention bottlenecks improves fusion performance, at the same time reducing computational cost.
    
		      <img width="800" class="center" src="assets/images/bottlenecks-ablation-combined.png">
		      			</br>
		      </br>

                                  The attention is particularly focused on sound source regions in the video that contain motion, eg. the fingertips on the piano, the hands on the string instrument, faces of humans.  The bottlenecks in MBT further force the attention to be localised to smaller regions of the images (i.e the mouth of the baby on the top left and the mouth of the woman singing on the bottom right)
             
		  		  <img width="800" class="center" src="assets/images/visualisations.png">
             
		  
		  
		</div>







              

               <!-- <table align=center width=800px>
                  <img width = "500" src="assets/images/splash.png">
                </table>
              -->
 
          



              
              
              
              <div align="center" class="row section topspace"> 
                <h2 class="section-title"><span>Publication</span></h2>     
                <div class="ref">
                <div class="authors">
                A. Nagrani,
		S. Yang, 
		A. Arnab, 
		A. Jansen, 
                C. Schmid,
                C. Sun
                </div>
                <div class="title">
                <a href="https://arxiv.org/pdf/2107.00135.pdf">
                Attention Bottlenecks for Multimodal Fusion
                </a> &nbsp;
                </div>
                <div class="conf">
               	ArXiv,  2021
                </div>
                <div class="links">
                <a onclick="if (document.getElementById(&quot;BIBNagrani21c&quot;).style.display==&quot;none&quot;) document.getElementById(&quot;BIBNagrani21c&quot;).style.display=&quot;block&quot;; else document.getElementById(&quot;BIBNagrani21c&quot;).style.display=&quot;none&quot;;"> Bibtex </a> |  
                <a href="https://arxiv.org/pdf/2107.00135.pdf"> ArXiv</a>    
                </div>
                <div style="display: none;" class="BibtexExpand" id="BIBNagrani21c">
                <pre class="bibtex">
@InProceeding{Nagrani21c,
  author       = "Arsha Nagrani and Shan Yang and Anurag Arnab and Cordelia Schmid and Chen Sun",
  title        = "Attention Bottlenecks for Multimodal Fusion",
  booktitle    = "arXiv
preprint arXiv:",
  year         = "2021",
}
                </pre>
                
                </div>

                </div> 
                </div>
               </div>
	       		</center>

               <br><br>
               <script xml:space="preserve" language="JavaScript">
                hideallbibs();
              </script>
            </body>
            </html>

